# AI-Model-Grader
Automated Evaluation Pipeline for AI Model Responses  
A Python-based system for benchmarking LLM outputs against medical domain answer keys. Features PDF parsing, text normalization, and multi-model scoring (GPT, Gemini, Claude, etc.). Built with Python, pandas, and regex for efficient answer comparison.

### Key Features:
- Robust PDF processing for answer key and model responses
- Medical terminology-aware text normalization
- Multi-model performance benchmarking
- Automated Excel report generation

### Ideal for:
- Educational/medical domain answer validation
- AI model response quality assurance
- Technical competency in text processing and evaluation pipelines
